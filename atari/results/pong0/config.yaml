action_dim: 1
annealing: true
annealing_start: 50000
annealing_steps: 1000000
ddqn: false
device: mps
episode_max_len: 60000
epsilon: 1.0
event: negative
final_epsilon: 0.1
folder_location: ./results/
folder_name: pong
frame_skip: 4
game_name: pong
gamma: 1.0
history_len: 4
is_learning: true
is_testing: true
learning_frequency: 4
learning_rate: 0.00025
max_start_nullops: 30
minibatch_size: 32
network_size: nature
normalize: 255.0
num_epochs: 201
num_experiments: 1
random_seed: 1
rendering: false
repeat_action_probability: 0.0
replay_max_size: 1000000
replay_min_size: 50000
reward_dim: 1
screen_size: 84
sided_Q: grit
steps_per_epoch: 250000
steps_per_test: 125000
sticky_actions: true
terminal_on_life_loss: false
test: false
test_epsilon: 0
update_freq: 10000
